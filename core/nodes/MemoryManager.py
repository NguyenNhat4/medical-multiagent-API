# Core framework import
from core.pocketflow import AsyncNode

# Standard library imports
import logging

# Configure logging for this module with Vietnam timezone
from utils.timezone_utils import setup_vietnam_logging
from config.logging_config import logging_config

if logging_config.USE_VIETNAM_TIMEZONE:
    logger = setup_vietnam_logging(__name__,
                                 level=getattr(logging, logging_config.LOG_LEVEL.upper()),
                                 format_str=logging_config.LOG_FORMAT)
else:
    logger = logging.getLogger(__name__)
    logger.setLevel(getattr(logging, logging_config.LOG_LEVEL.upper()))


class MemoryManager(AsyncNode):
    """
    Memory Manager - Orchestrator node that analyzes conversation and existing memories
    to decide which operations (INSERT/UPDATE/DELETE) should be performed.

    This node uses LLM to intelligently determine operations that will be executed
    by specialized worker nodes (AddMemory, UpdateMemory, DeleteMemory).
    """

    async def prep_async(self, shared):
        user_id = shared.get("user_id")
        query = shared.get("original_query") or shared.get("input", "")
        context_summary = shared.get("context_summary", "")
        role = shared.get("role", "")
        # Try multiple fields for AI response
        ai_response = (shared.get("final_answer", "") or
                      shared.get("response", "") or
                      shared.get("explain", "") or
                      (shared.get("answer_obj", {}).get("explain", "") if isinstance(shared.get("answer_obj"), dict) else ""))
        relevant_memories = shared.get("relevant_memories", [])

        logger.info(f"ðŸŽ¯ [MemoryManager] PREP - User ID: {user_id}, Query: {query[:50] if query else 'None'}...")
        logger.info(f"ðŸŽ¯ [MemoryManager] PREP - Analyzing {len(relevant_memories)} existing memories")

        return {
            "user_id": user_id,
            "query": query,
            "context_summary": context_summary,
            "role": role,
            "ai_response": ai_response,
            "relevant_memories": relevant_memories
        }

    async def exec_async(self, inputs):
        from utils.llm import call_llm
        from utils.parsing import parse_yaml_with_schema
        from utils.llm.call_llm import APIOverloadException
        from config.timeout_config import timeout_config
        from utils.role_enum import RoleEnum, ROLE_DISPLAY_NAME

        user_id = inputs["user_id"]
        query = inputs["query"]
        context_summary = inputs["context_summary"]
        role = inputs["role"]
        ai_response = inputs["ai_response"]
        relevant_memories = inputs["relevant_memories"]

        if not user_id:
            logger.warning("ðŸŽ¯ [MemoryManager] EXEC - Missing user_id, cannot manage memories")
            return {
                "success": False,
                "operations": {"insert": [], "update": [], "delete": []},
                "reason": "Missing user_id"
            }

        if not query:
            logger.warning("ðŸŽ¯ [MemoryManager] EXEC - Missing query, cannot manage memories")
            return {
                "success": False,
                "operations": {"insert": [], "update": [], "delete": []},
                "reason": "Missing query"
            }

        # Format existing memories for the prompt
        vietnameseRole = ROLE_DISPLAY_NAME.get(RoleEnum(role), "NgÆ°á»i dÃ¹ng") if role else "NgÆ°á»i dÃ¹ng"

        memories_context = ""
        if relevant_memories:
            memories_list = []
            for i, mem in enumerate(relevant_memories[:10], 1):  # Show top 10
                memories_list.append(
                    f"  - ID: {mem.get('id')}\n"
                    f"    Ná»™i dung: {mem.get('query', '')}\n"
                    f"    Score: {mem.get('score', 0):.3f}"
                )
            memories_context = f"\n# CÃC MEMORY ÄÃƒ Tá»’N Táº I (Top 10):\n" + "\n".join(memories_list)
        else:
            memories_context = "\n# CÃC MEMORY ÄÃƒ Tá»’N Táº I: KhÃ´ng cÃ³ memory nÃ o."

        prompt = f"""
# NHIá»†M Vá»¤:
Báº¡n lÃ  Memory Manager - há»‡ thá»‘ng quáº£n lÃ½ bá»™ nhá»› thÃ´ng minh. PhÃ¢n tÃ­ch há»™i thoáº¡i vÃ  quyáº¿t Ä‘á»‹nh cÃ¡c thao tÃ¡c cáº§n thá»±c hiá»‡n.

# Bá»I Cáº¢NH Há»˜I THOáº I:
- TÃ³m táº¯t há»™i thoáº¡i trÆ°á»›c: {context_summary}
- NgÆ°á»i dÃ¹ng ({vietnameseRole}): "{query}"
- AI tráº£ lá»i: "{ai_response[:300]}..."
{memories_context}

# CÃC THAO TÃC:
1. **INSERT**: ThÃªm memory má»›i - thÃ´ng tin hoÃ n toÃ n má»›i vÃ  quan trá»ng
2. **UPDATE**: Cáº­p nháº­t memory cÅ© - thÃ´ng tin Ä‘Ã£ thay Ä‘á»•i/bá»• sung
3. **DELETE**: XÃ³a memory cÅ© - thÃ´ng tin sai/lá»—i thá»i/khÃ´ng cÃ²n liÃªn quan

# QUY Táº®C:
- INSERT: ThÃ´ng tin cÃ¡ nhÃ¢n má»›i (tÃªn, tuá»•i, nghá»), sá»©c khá»e, sá»Ÿ thÃ­ch, gia Ä‘Ã¬nh chÆ°a cÃ³
- UPDATE: ThÃ´ng tin cÅ© cáº§n cáº­p nháº­t (tuá»•i má»›i, cÃ´ng viá»‡c má»›i, tÃ¬nh tráº¡ng sá»©c khá»e thay Ä‘á»•i)
- DELETE: ThÃ´ng tin trong memory hoÃ n toÃ n sai hoáº·c ngÆ°á»i dÃ¹ng Ä‘Ã£ sá»­a/phá»§ nháº­n
- SKIP ALL: ChÃ o há»i xÃ£ giao, thÃ´ng tin tá»•ng quÃ¡t, hoáº·c Ä‘Ã£ Ä‘áº§y Ä‘á»§ trong memory

# YÃŠU Cáº¦U Äá»ŠNH Dáº NG (QUAN TRá»ŒNG):
- Sá»­ dá»¥ng Block Scalar (|) cho vÄƒn báº£n
- Tá»• chá»©c operations theo loáº¡i: insert_operations, update_operations, delete_operations
- Má»—i operation cÃ³: memory_id (náº¿u UPDATE/DELETE), content (náº¿u INSERT/UPDATE)

# VÃ Dá»¤:
```yaml
insert_operations:
  - content: |
      NgÆ°á»i dÃ¹ng cÃ³ sá»Ÿ thÃ­ch Ä‘á»c sÃ¡ch triáº¿t há»c
update_operations:
  - memory_id: "abc-123"
    content: |
      NgÆ°á»i dÃ¹ng An, 30 tuá»•i (cáº­p nháº­t tá»« 29), nghá» giÃ¡o viÃªn
delete_operations:
  - memory_id: "xyz-456"
reason: |
  Cáº­p nháº­t tuá»•i, thÃªm sá»Ÿ thÃ­ch má»›i, xÃ³a thÃ´ng tin sai
importance: "high"
```

Tráº£ vá» duy nháº¥t má»™t block code YAML:
"""

        logger.info(f"ðŸŽ¯ [MemoryManager] EXEC - Analyzing operations with LLM")

        resp = call_llm(prompt, fast_mode=True, max_retry_time=timeout_config.LLM_RETRY_TIMEOUT)

        result = parse_yaml_with_schema(
            resp,
            required_fields=["reason"],
            optional_fields=["insert_operations", "update_operations", "delete_operations", "importance"],
            field_types={
                "insert_operations": list,
                "update_operations": list,
                "delete_operations": list,
                "reason": str,
                "importance": str
            }
        )

        assert isinstance(result, dict), f"Failed to parse LLM response, got: {resp}"

        insert_ops = result.get("insert_operations", [])
        update_ops = result.get("update_operations", [])
        delete_ops = result.get("delete_operations", [])
        reason = result.get("reason", "")
        importance = result.get("importance", "medium")

        total_ops = len(insert_ops) + len(update_ops) + len(delete_ops)
        logger.info(f"ðŸŽ¯ [MemoryManager] EXEC - Decided {total_ops} operations: "
                  f"INSERT={len(insert_ops)}, UPDATE={len(update_ops)}, DELETE={len(delete_ops)}")
        logger.info(f"ðŸŽ¯ [MemoryManager] EXEC - Reason: {reason}")

        return {
            "success": True,
            "operations": {
                "insert": insert_ops,
                "update": update_ops,
                "delete": delete_ops
            },
            "reason": reason,
            "importance": importance,
            "user_id": user_id
        }

    async def exec_fallback_async(self, inputs, exc):
        logger.error(f"ðŸŽ¯ [MemoryManager] FALLBACK - Failed after {self.max_retries} retries: {exc}")
        user_id = inputs.get("user_id")
        return {
            "success": True,
            "operations": {"insert": [], "update": [], "delete": []},
            "reason": "Failed to analyze operations, skipping",
            "importance": "low",
            "user_id": user_id
        }

    async def post_async(self, shared, prep_res, exec_res):
        # Store operation decisions in shared state for worker nodes
        shared["memory_operations"] = exec_res.get("operations", {})
        shared["memory_manager_reason"] = exec_res.get("reason", "")
        shared["memory_importance"] = exec_res.get("importance", "medium")

        operations = exec_res.get("operations", {})
        insert_count = len(operations.get("insert", []))
        update_count = len(operations.get("update", []))
        delete_count = len(operations.get("delete", []))

        total = insert_count + update_count + delete_count

        if total == 0:
            logger.info(f"ðŸŽ¯ [MemoryManager] POST - No operations needed, returning 'skip'")
            return "skip"  # No operations, skip to end

        # Return specific routes based on what operations exist
        # This allows conditional routing in the flow
        routes = []
        if insert_count > 0:
            routes.append("insert")
        if update_count > 0:
            routes.append("update")
        if delete_count > 0:
            routes.append("delete")

        logger.info(f"ðŸŽ¯ [MemoryManager] POST - Operations planned: "
                   f"INSERT={insert_count}, UPDATE={update_count}, DELETE={delete_count}")
        logger.info(f"ðŸŽ¯ [MemoryManager] POST - Operations details: {operations}")
        logger.info(f"ðŸŽ¯ [MemoryManager] POST - Returning routes: {routes}")

        # Return first route (or "default" if routing doesn't support multiple returns)
        # For now, return "default" and let worker nodes check if they have work
        return "default"  # Proceed to worker nodes
