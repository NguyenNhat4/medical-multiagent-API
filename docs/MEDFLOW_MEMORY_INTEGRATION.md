# MedFlow Memory Integration Guide

## Overview

MedFlow has been updated to use the new **async parallel batch memory architecture** for improved performance and scalability.

## Changes Made

### 1. Flow Class Update
```python
# OLD:
from pocketflow import Flow
class MedFlow(Flow):

# NEW:
from core.pocketflow import AsyncFlow
class MedFlow(AsyncFlow):
```

**Why**: AsyncFlow supports async nodes (AsyncNode, AsyncParallelBatchNode) which are essential for parallel memory operations.

### 2. Node Replacements

#### OLD Architecture:
```python
save_memory = SaveToMemory(max_retries=3)
```
- Single node handling all memory operations
- Sequential execution (INSERT â†’ UPDATE â†’ DELETE)
- LLM decides + executes in same node

#### NEW Architecture:
```python
memory_manager = MemoryManager(max_retries=2)  # Orchestrator
add_memory = AddMemory()                       # INSERT worker
update_memory = UpdateMemory()                 # UPDATE worker
delete_memory = DeleteMemory()                 # DELETE worker
```
- Separation of concerns: decision vs execution
- Parallel execution of operations
- Better error handling per operation type

### 3. Flow Integration Points

Memory operations happen at 3 key points in MedFlow:

#### Point 1: Direct Response (no retrieval needed)
```python
main_decision - "default" >> memory_manager
```
When user query can be answered directly without KB retrieval.

#### Point 2: After Retrieval
```python
retrieve_with_demuc >> memory_manager  # Parallel save
rag_agent - "compose_answer" >> memory_manager
```
After retrieving from knowledge base, save relevant information to memory.

#### Point 3: Worker Execution
```python
memory_manager - "default" >> add_memory     # INSERT operations
memory_manager - "default" >> update_memory  # UPDATE operations
memory_manager - "default" >> delete_memory  # DELETE operations
memory_manager - "skip" >> None              # No operations needed
```
MemoryManager routes to appropriate workers based on LLM decisions.

## Flow Execution Path

### Example: User provides new health information

```
User Input: "TÃ´i 25 tuá»•i, bá»‹ tiá»ƒu Ä‘Æ°á»ng type 2"
    â†“
IngestQuery â†’ RetrieveFromMemory (get top 10 memories)
    â†“
MainDecision â†’ MemoryManager (async LLM call)
    â†“ (decides: INSERT new info about age & diabetes)
    â”œâ”€â†’ AddMemory (parallel insert 2 memories) â”€â”€â”
    â”œâ”€â†’ UpdateMemory (no operations) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤â”€â†’ Continue
    â””â”€â†’ DeleteMemory (no operations) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: User updates existing information

```
User Input: "Giá» tÃ´i 26 tuá»•i rá»“i"
    â†“
RetrieveFromMemory â†’ finds memory "ID-123: NgÆ°á»i dÃ¹ng 25 tuá»•i"
    â†“
MemoryManager (decides: UPDATE ID-123)
    â†“
    â”œâ”€â†’ AddMemory (no operations) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”œâ”€â†’ UpdateMemory (update ID-123 in parallel) â”¤â”€â†’ Continue
    â””â”€â†’ DeleteMemory (no operations) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Performance Benefits

### Sequential Execution (OLD)
```
Total Time = T_llm_decision + T_insert1 + T_insert2 + T_update1 + T_delete1
Example: 200ms + 100ms + 100ms + 100ms + 100ms = 600ms
```

### Parallel Execution (NEW)
```
Total Time = T_llm_decision + max(T_insert_batch, T_update_batch, T_delete_batch)
Example: 200ms + max(100ms, 100ms, 100ms) = 300ms
Speedup: 2x faster!
```

With more operations, speedup can be 5-10x!

## Async Execution Model

### How AsyncFlow Works

1. **Sync Nodes** (IngestQuery, RagAgent, etc.):
   - Run normally using `_run(shared)`
   - Block until completion

2. **Async Nodes** (MemoryManager, AddMemory, UpdateMemory, DeleteMemory):
   - Run using `_run_async(shared)`
   - Non-blocking with `await`

3. **Hybrid Execution**:
   - AsyncFlow automatically detects node type
   - Calls `_run()` for sync nodes
   - Calls `_run_async()` for async nodes
   - See pocketflow.py:85

### Node Type Detection
```python
# From AsyncFlow._orch_async (pocketflow.py:85)
last_action = await curr._run_async(shared) if isinstance(curr, AsyncNode) else curr._run(shared)
```

## Error Handling

### MemoryManager Fallbacks
- **LLM Timeout**: Returns empty operations (skip all)
- **API Overload**: Returns empty operations (skip all)
- **Parse Error**: Returns empty operations (skip all)

### Worker Node Errors
- **AddMemory**: Failed inserts logged, continues with others
- **UpdateMemory**: Failed updates logged, continues with others
- **DeleteMemory**: Batch operation, all-or-nothing per batch

### Retry Strategy
```python
memory_manager = MemoryManager(max_retries=2)  # Retries LLM call
```
- Worker nodes don't need retries (operations are idempotent)
- Failed operations are logged with full details

## Monitoring & Debugging

### Logging Emojis
- ğŸ§  **RetrieveFromMemory**: Retrieving memories
- ğŸ¯ **MemoryManager**: Deciding operations
- â• **AddMemory**: INSERT operations
- ğŸ”„ **UpdateMemory**: UPDATE operations
- ğŸ—‘ï¸ **DeleteMemory**: DELETE operations

### Shared State Variables
```python
shared["relevant_memories"]        # From RetrieveFromMemory
shared["memory_operations"]        # From MemoryManager
shared["memory_manager_reason"]    # LLM decision reason
shared["memory_importance"]        # high/medium/low
shared["add_memory_result"]        # AddMemory results
shared["update_memory_result"]     # UpdateMemory results
shared["delete_memory_result"]     # DeleteMemory results
```

### Example Logs
```
ğŸ§  [RetrieveFromMemory] PREP - User ID: user123, Query: TÃ´i 25 tuá»•i...
ğŸ§  [RetrieveFromMemory] EXEC - Retrieved 3 memories
ğŸ¯ [MemoryManager] PREP - Analyzing 3 existing memories
ğŸ¯ [MemoryManager] EXEC - Decided 2 operations: INSERT=1, UPDATE=1, DELETE=0
â• [AddMemory] PREP - 1 insert operation(s)
â• [AddMemory] EXEC [1] - INSERT successful - 'NgÆ°á»i dÃ¹ng 25 tuá»•i'...
â• [AddMemory] POST - Completed: 1/1 successful (parallel execution)
ğŸ”„ [UpdateMemory] PREP - 1 update operation(s)
ğŸ”„ [UpdateMemory] EXEC [1] - UPDATE [abc-123] successful - 'NgÆ°á»i dÃ¹ng...'
ğŸ”„ [UpdateMemory] POST - Completed: 1/1 successful (parallel)
```

## Testing

### Unit Testing
Test each node independently:
```python
# Test MemoryManager
shared = {
    "user_id": "test123",
    "query": "TÃ´i 25 tuá»•i",
    "relevant_memories": [...]
}
result = await memory_manager.run_async(shared)
```

### Integration Testing
Test full flow:
```python
flow = MedFlow()
shared = {"input": "TÃ´i 25 tuá»•i, bá»‹ tiá»ƒu Ä‘Æ°á»ng"}
result = await flow.run_async(shared)
```

### Load Testing
Parallel execution should handle high load better:
- 100 concurrent requests with 5 operations each
- OLD: ~60s total
- NEW: ~12s total (5x speedup)

## Migration Checklist

- [x] Update Flow class to AsyncFlow
- [x] Replace SaveToMemory with new nodes
- [x] Connect MemoryManager to worker nodes
- [x] Add proper routing ("default" and "skip")
- [x] Update imports
- [x] Test async execution
- [ ] Monitor production performance
- [ ] Compare metrics with old architecture

## Backward Compatibility

The old `SaveToMemory` node is still available:
```python
# To revert to old architecture (not recommended):
from ..nodes.SaveToMemory import SaveToMemory
save_memory = SaveToMemory(max_retries=3)
```

However, the new architecture is recommended for:
- Better performance (parallel execution)
- Better observability (separate logs per operation)
- Better scalability (can handle more operations)
- Better error handling (failures isolated per operation)

## Next Steps

1. **Monitor Performance**: Track execution times in production
2. **Optimize Batch Sizes**: Tune top_k in RetrieveFromMemory
3. **Add Metrics**: Track INSERT/UPDATE/DELETE counts
4. **A/B Testing**: Compare old vs new architecture
5. **Scale Workers**: If needed, can add more parallel workers

## Troubleshooting

### Issue: "AsyncFlow not found"
**Solution**: Update import to `from core.pocketflow import AsyncFlow`

### Issue: "Worker nodes not executing"
**Solution**: Check MemoryManager routing - ensure "default" edge exists

### Issue: "Parallel execution not working"
**Solution**: Verify nodes use AsyncParallelBatchNode (AddMemory, UpdateMemory)

### Issue: "Flow hanging"
**Solution**: Check for missing edges or None destinations

### Issue: "Memory operations not saved"
**Solution**: Check shared["memory_operations"] structure from MemoryManager
